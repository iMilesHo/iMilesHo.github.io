<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Adaboost (Adaptive Boosting) Homework | Yuanlai He (Miles) </title> <meta name="author" content="Miles (Yuanlai) Ho"> <meta name="description" content="About Adaboost (Adaptive Boosting)"> <meta name="keywords" content="Software Development Engineer"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/command-line.png?0c818eda30e553ba2f0d187ca37db021"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://imilesho.github.io/blog/2023/adaboost/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Yuanlai He (Miles) </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Adaboost (Adaptive Boosting) Homework</h1> <p class="post-meta"> December 29, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/machinelearning"> <i class="fa-solid fa-hashtag fa-sm"></i> MachineLearning</a>     ·   <a href="/blog/category/posts"> <i class="fa-solid fa-tag fa-sm"></i> posts</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="adaboost-adaptive-boosting-homework">Adaboost (Adaptive Boosting) Homework</h2> <p><strong>Question 1</strong>. Use 3 weak learners (decision stumps) to design an AdaBoost classifier trained with the following data (with Play Baseball Today as the target attribute) showing calculations worked out by hand. Provide the final decision function for the classifier.</p> <table> <thead> <tr> <th>Number of Previous Days of Rain</th> <th>Play Baseball Today</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>Yes</td> </tr> <tr> <td>1</td> <td>Yes</td> </tr> <tr> <td>2</td> <td>Yes</td> </tr> <tr> <td>3</td> <td>No</td> </tr> <tr> <td>4</td> <td>No</td> </tr> <tr> <td>5</td> <td>No</td> </tr> <tr> <td>6</td> <td>Yes</td> </tr> <tr> <td>7</td> <td>Yes</td> </tr> <tr> <td>8</td> <td>Yes</td> </tr> <tr> <td>9</td> <td>No</td> </tr> </tbody> </table> <h2 id="solution">Solution:</h2> <p>AdaBoost is a boosting algorithm that combines multiple weak learners to form a strong learner. The weak learner is a decision stump which is a one level decision tree.</p> <ol> <li>for the first weak learner: (1) Initialize the weights of all instances to 1/10. (2) To find the best decision stump (i.e., the best attribute and threshold) that minimizes the weighted error, I test each threshold from 0 to 9 by calculating the weighted error. The weighted error is calculated by summing the weights of all instances that are misclassified by the decision stump. The math formula is: \(\epsilon = \sum_{i=1}^{n}w_iI(y_i \neq h(x_i))\) where $w_i$ is the weight of instance $i$, $y_i$ is the true label of instance $i$, $h(x_i)$ is the predicted label of instance $i$, and $I(y_i \neq h(x_i))$ is the indicator function that returns 1 if $y_i \neq h(x_i)$ and 0 otherwise.</li> </ol> <table> <thead> <tr> <th>Threshold</th> <th>Weighted Error</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>0.5</td> </tr> <tr> <td>1</td> <td>0.4</td> </tr> <tr> <td>2</td> <td>0.3</td> </tr> <tr> <td>3</td> <td>0.4</td> </tr> <tr> <td>4</td> <td>0.5</td> </tr> <tr> <td>5</td> <td>0.4</td> </tr> <tr> <td>6</td> <td>0.5</td> </tr> <tr> <td>7</td> <td>0.4</td> </tr> <tr> <td>8</td> <td>0.3</td> </tr> <tr> <td>9</td> <td>0.4</td> </tr> </tbody> </table> <p>(3) The threshold with the minimum weighted error is 2 and 8. I choose 2 as the threshold which is the first threshold.</p> <p>(4) The decision stump is: if Number of Previous Days of Rain &lt;= 2, then Play Baseball Today = Yes, else Play Baseball Today = No.</p> <p>(5) Calculate the Alpha value (performance of the stump) for the decision stump. The math formula is: \(\alpha = \frac{1}{2}ln(\frac{1-\epsilon}{\epsilon})\) where $\epsilon$ is the weighted error of the decision stump.</p> \[\alpha = \frac{1}{2}ln(\frac{1-0.3}{0.3}) = 0.4237\] <p>(6) Update the weights of all instances. The math formula is: \(w_i = w_i * e^{-\alpha y_i h(x_i)}\) where $w_i$ is the weight of instance $i$, $y_i$ is the true label of instance $i$, $h(x_i)$ is the predicted label of instance $i$, and $\alpha$ is the performance of the decision stump. Correctly classified instances will have $-\alpha y_i h(x_i)=1$, and misclassified instances will have $-\alpha y_i h(x_i)=-1$.</p> <table> <thead> <tr> <th>Number of Previous Days of Rain</th> <th>Play Baseball Today</th> <th>Weight</th> <th>Updated Weight</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>Yes</td> <td>0.1</td> <td>0.06546</td> </tr> <tr> <td>1</td> <td>Yes</td> <td>0.1</td> <td>0.06546</td> </tr> <tr> <td>2</td> <td>Yes</td> <td>0.1</td> <td>0.06546</td> </tr> <tr> <td>3</td> <td>No</td> <td>0.1</td> <td>0.06546</td> </tr> <tr> <td>4</td> <td>No</td> <td>0.1</td> <td>0.06546</td> </tr> <tr> <td>5</td> <td>No</td> <td>0.1</td> <td>0.06546</td> </tr> <tr> <td>6</td> <td>Yes</td> <td>0.1</td> <td>0.1528</td> </tr> <tr> <td>7</td> <td>Yes</td> <td>0.1</td> <td>0.1528</td> </tr> <tr> <td>8</td> <td>Yes</td> <td>0.1</td> <td>0.1528</td> </tr> <tr> <td>9</td> <td>No</td> <td>0.1</td> <td>0.06546</td> </tr> </tbody> </table> <p>(7) Normalize the weights of all instances. The math formula is: \(w_i = \frac{w_i}{\sum_{i=1}^{n}w_i}\) where $w_i$ is the weight of instance $i$.</p> <table> <thead> <tr> <th>Number of Previous Days of Rain</th> <th>Play Baseball Today</th> <th>Normalized Weight</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>Yes</td> <td>0.0714</td> </tr> <tr> <td>1</td> <td>Yes</td> <td>0.0714</td> </tr> <tr> <td>2</td> <td>Yes</td> <td>0.0714</td> </tr> <tr> <td>3</td> <td>No</td> <td>0.0714</td> </tr> <tr> <td>4</td> <td>No</td> <td>0.0714</td> </tr> <tr> <td>5</td> <td>No</td> <td>0.0714</td> </tr> <tr> <td>6</td> <td>Yes</td> <td>0.1667</td> </tr> <tr> <td>7</td> <td>Yes</td> <td>0.1667</td> </tr> <tr> <td>8</td> <td>Yes</td> <td>0.1667</td> </tr> <tr> <td>9</td> <td>No</td> <td>0.0714</td> </tr> </tbody> </table> <p>The incorrectly classified instances have higher weights than the correctly classified instances.</p> <ol> <li>for the second weak learner: (1) The weights of all instances are updated in the first weak learner. (2) Calculate the weighted error for each threshold from 0 to 9.</li> </ol> <table> <thead> <tr> <th>Threshold</th> <th>Weighted Error</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>0.642857</td> </tr> <tr> <td>1</td> <td>0.571429</td> </tr> <tr> <td>2</td> <td>0.500000</td> </tr> <tr> <td>3</td> <td>0.571429</td> </tr> <tr> <td>4</td> <td>0.642857</td> </tr> <tr> <td>5</td> <td>0.714286</td> </tr> <tr> <td>6</td> <td>0.547619</td> </tr> <tr> <td>7</td> <td>0.380952</td> </tr> <tr> <td>8</td> <td>0.214286</td> </tr> <tr> <td>9</td> <td>0.285714</td> </tr> </tbody> </table> <p>(3) The threshold with the minimum weighted error is 8. I choose 8 as the threshold which is the second threshold.</p> <p>(4) The decision stump is: if Number of Previous Days of Rain &lt;= 8, then Play Baseball Today = Yes, else Play Baseball Today = No.</p> <p>(5) Calculate the Alpha value. \(\alpha = \frac{1}{2}ln(\frac{1-0.214286}{0.0.214286}) = 0.650\)</p> <p>(6) Update the weights of all instances and normalize the weights of all instances.</p> <table> <thead> <tr> <th>Number of Previous Days of Rain</th> <th>Play Baseball Today</th> <th>Weight</th> <th>Updated Weight</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>Yes</td> <td>0.0714</td> <td>0.045455</td> </tr> <tr> <td>1</td> <td>Yes</td> <td>0.0714</td> <td>0.045455</td> </tr> <tr> <td>2</td> <td>Yes</td> <td>0.0714</td> <td>0.045455</td> </tr> <tr> <td>3</td> <td>No</td> <td>0.0714</td> <td>0.166667</td> </tr> <tr> <td>4</td> <td>No</td> <td>0.0714</td> <td>0.166667</td> </tr> <tr> <td>5</td> <td>No</td> <td>0.0714</td> <td>0.166667</td> </tr> <tr> <td>6</td> <td>Yes</td> <td>0.1667</td> <td>0.106061</td> </tr> <tr> <td>7</td> <td>Yes</td> <td>0.1667</td> <td>0.106061</td> </tr> <tr> <td>8</td> <td>Yes</td> <td>0.1667</td> <td>0.106061</td> </tr> <tr> <td>9</td> <td>No</td> <td>0.0714</td> <td>0.045455</td> </tr> </tbody> </table> <ol> <li>for the third weak learner: (1) The weights of all instances are updated in the second weak learner.</li> </ol> <p>(2) Calculate the weighted error for each threshold from 0 to 9.</p> <table> <thead> <tr> <th>Threshold</th> <th>Weighted Error</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>0.409091</td> </tr> <tr> <td>1</td> <td>0.363636</td> </tr> <tr> <td>2</td> <td>0.318182</td> </tr> <tr> <td>3</td> <td>0.484848</td> </tr> <tr> <td>4</td> <td>0.651515</td> </tr> <tr> <td>5</td> <td>0.818182</td> </tr> <tr> <td>6</td> <td>0.712121</td> </tr> <tr> <td>7</td> <td>0.606061</td> </tr> <tr> <td>8</td> <td>0.500000</td> </tr> <tr> <td>9</td> <td>0.545455</td> </tr> </tbody> </table> <p>(3) The threshold with the minimum weighted error is 2. I choose 2 as the threshold which is the third threshold.</p> <p>(4) The decision stump is: if Number of Previous Days of Rain &lt;= 2, then Play Baseball Today = Yes, else Play Baseball Today = No.</p> <p>(5) Calculate the Alpha value. \(\alpha = \frac{1}{2}ln(\frac{1-0.318182}{0.318182}) = 0.381\)</p> <p>(6) Update the weights of all instances and normalize the weights of all instances. | Number of Previous Days of Rain | Play Baseball Today | Weight | Updated Weight | | — | — | — | — | | 0 | Yes | 0.045455 | 0.033333 | 1 | Yes | 0.045455 | 0.033333 | 2 | Yes | 0.045455 | 0.033333 | 3 | No | 0.166667 | 0.122222 | 4 | No | 0.166667 | 0.122222 | 5 | No | 0.166667 | 0.122222 | 6 | Yes | 0.106061 | 0.166667 | 7 | Yes | 0.106061 | 0.166667 | 8 | Yes | 0.106061 | 0.166667 | 9 | No | 0.045455 | 0.033333</p> <ol> <li>In summary (1) The Final Weight Table</li> </ol> <table> <thead> <tr> <th>Data Points</th> <th>Initial Weights</th> <th>Weight of 1st Weak Learner</th> <th>Weight of 2nd Weak Learner</th> <th>Weight of 3rd Weak Learner</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>0.1</td> <td>0.071429</td> <td>0.045455</td> <td>0.033333</td> </tr> <tr> <td>1</td> <td>0.1</td> <td>0.071429</td> <td>0.045455</td> <td>0.033333</td> </tr> <tr> <td>2</td> <td>0.1</td> <td>0.071429</td> <td>0.045455</td> <td>0.033333</td> </tr> <tr> <td>3</td> <td>0.1</td> <td>0.071429</td> <td>0.166667</td> <td>0.122222</td> </tr> <tr> <td>4</td> <td>0.1</td> <td>0.071429</td> <td>0.166667</td> <td>0.122222</td> </tr> <tr> <td>5</td> <td>0.1</td> <td>0.071429</td> <td>0.166667</td> <td>0.122222</td> </tr> <tr> <td>6</td> <td>0.1</td> <td>0.166667</td> <td>0.106061</td> <td>0.166667</td> </tr> <tr> <td>7</td> <td>0.1</td> <td>0.166667</td> <td>0.106061</td> <td>0.166667</td> </tr> <tr> <td>8</td> <td>0.1</td> <td>0.166667</td> <td>0.106061</td> <td>0.166667</td> </tr> <tr> <td>9</td> <td>0.1</td> <td>0.071429</td> <td>0.045455</td> <td>0.033333</td> </tr> </tbody> </table> <p>(2) Alphas for Weak Learners: For the 1st decision stump (threshold=2): Alpha = 0.424 For the 2nd decision stump (threshold=8): Alpha = 0.650 For the 3rd decision stump (threshold=2): Alpha = 0.381</p> <p>(3) Final Decision Function:</p> <p>\(f(x) = sign(\sum_{t=1}^{T}\alpha_th_t(x))\) where $T$ is the number of weak learners, $\alpha_t$ is the performance of the $t$th weak learner, and $h_t(x)$ is the prediction of the $t$th weak learner.</p> <p>\(f(x) = sign(0.424h_1(x) + 0.650h_2(x) + 0.381h_3(x))\) The sign of this sum will give us the final classification.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/ANN-Backpropagation/">ANN Backpropagation Process</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/IAM-and-IAM-Identity-Center/">IAM and IAM Identity Center</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/the-shell/">The Shell Command Line and File System Basics</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Positive-defnite-matrices/">Linear Algebra Foundation based Homework Problems - Positive defnite matrices</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/LinearAlgebraFoundation/">Linear Algebra Foundation</a> </li> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"iMilesHo/iMilesHo.github.io","data-repo-id":"","data-category":"Comments","data-category-id":"","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Miles (Yuanlai) Ho. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>
<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://imilesho.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://imilesho.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-16T05:02:22+00:00</updated><id>https://imilesho.github.io/feed.xml</id><title type="html">Yuanlai He (Miles)</title><subtitle>Full-time Software engineer (SWE) for 2 years | Individual iOS developer | Java/JavaScript/Swift/Python </subtitle><entry><title type="html">Heap vs. Stack Memory in Java</title><link href="https://imilesho.github.io/blog/2024/tokenization-embedding-layer-copy/" rel="alternate" type="text/html" title="Heap vs. Stack Memory in Java"/><published>2024-02-15T12:00:00+00:00</published><updated>2024-02-15T12:00:00+00:00</updated><id>https://imilesho.github.io/blog/2024/tokenization-embedding-layer%20copy</id><content type="html" xml:base="https://imilesho.github.io/blog/2024/tokenization-embedding-layer-copy/"><![CDATA[<p>Understanding the difference between the heap and the stack is fundamental to grasping how Java manages memory. Both the heap and the stack are parts of the memory used by a Java Virtual Machine (JVM), but they serve different purposes and have different behaviors.</p> <h2 id="stack">Stack</h2> <p><strong>Functionality</strong>: The stack is used for managing and executing thread execution. It stores primitive values that are specific to a method and references to objects in the heap that are referred to from the method.</p> <p><strong>Method Execution</strong>: When a method is called, a block (called a “stack frame”) is created on the stack. This block contains all the local variables and references used in the method, as well as the method’s call and return operations. Once the method has completed execution, its stack frame is removed from the stack.</p> <p><strong>Memory Management</strong>: Memory on the stack is automatically allocated and deallocated as methods are called and returned. This makes it very efficient, but the size of the stack is limited and is determined at the start of the application.</p> <p><strong>Lifespan</strong>: The stack has a very short lifespan. Variables only exist as long as the method that created them is running.</p> <h2 id="heap">Heap</h2> <p><strong>Functionality</strong>: The heap is used to store objects (instances of classes) and their attributes. It is where all the objects created by your Java application live.</p> <p><strong>Memory Allocation</strong>: Unlike the stack, memory allocation in the heap is dynamically managed. New objects are created in the heap, and Java’s garbage collector automatically removes objects that are no longer being used to free up memory.</p> <p><strong>Lifespan</strong>: Objects on the heap have a longer lifespan. They exist as long as there are references to them from other objects or from the stack. Once there are no more references to an object, it becomes eligible for garbage collection.</p> <p><strong>Performance</strong>: While the heap allows for dynamic memory allocation, managing it (especially the garbage collection process) can be more complex and slower compared to stack memory management.</p> <h2 id="key-differences">Key Differences</h2> <p><strong>Speed</strong>: Stack memory is faster to allocate and deallocate, as it works with a Last In, First Out (LIFO) principle. Heap memory, being more dynamically managed, requires more complex bookkeeping.</p> <p><strong>Scope</strong>: Stack memory is exclusive to a thread, meaning each thread has its own stack. The heap is application-wide; all threads share it.</p> <p><strong>Size</strong>: Stack memory is usually much smaller than heap memory. The exact sizes can be configured based on the application’s needs.</p> <p><strong>Usage</strong>: Primitives and method call stacks are stored in the stack memory, while objects and their fields are stored in the heap memory.</p> <p>Understanding these differences is crucial for efficient Java programming, especially for managing memory effectively, optimizing performance, and avoiding memory leaks or stack overflow errors.</p>]]></content><author><name></name></author><category term="notes"/><category term="Java"/><category term="MemoryManagement"/><summary type="html"><![CDATA[Understanding the difference between heap and stack memory in Java]]></summary></entry><entry><title type="html">RNN and LSTM</title><link href="https://imilesho.github.io/blog/2024/rnn-lstm/" rel="alternate" type="text/html" title="RNN and LSTM"/><published>2024-02-13T12:00:00+00:00</published><updated>2024-02-13T12:00:00+00:00</updated><id>https://imilesho.github.io/blog/2024/rnn-lstm</id><content type="html" xml:base="https://imilesho.github.io/blog/2024/rnn-lstm/"><![CDATA[<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BasicRNN</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">BasicRNN</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">RNN</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: [batch_size, seq_length]
</span>        <span class="n">embedded</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># embedded: [batch_size, seq_length, embedding_dim]
</span>        <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">rnn</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
        <span class="c1"># output: [batch_size, seq_length, hidden_dim]
</span>        <span class="c1"># hidden: [1, batch_size, hidden_dim] - only considering last layer's output
</span>        <span class="n">last_output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="c1"># last_output: [batch_size, hidden_dim]
</span>        <span class="n">prediction</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">last_output</span><span class="p">)</span>
        <span class="c1"># prediction: [batch_size, output_dim]
</span>        <span class="k">return</span> <span class="n">prediction</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LSTMModel</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">LSTMModel</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="c1"># Replace the basic RNN with an LSTM
</span>        <span class="n">self</span><span class="p">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">LSTM</span><span class="p">(</span><span class="n">embedding_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># x: [batch_size, seq_length]
</span>        <span class="n">embedded</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">embedding</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># embedded: [batch_size, seq_length, embedding_dim]
</span>        <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">cell</span><span class="p">)</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lstm</span><span class="p">(</span><span class="n">embedded</span><span class="p">)</span>
        <span class="c1"># output: [batch_size, seq_length, hidden_dim]
</span>        <span class="c1"># hidden: [1, batch_size, hidden_dim] - considering the last layer's last hidden state
</span>        <span class="c1"># cell: [1, batch_size, hidden_dim] - considering the last layer's last cell state
</span>        <span class="n">last_output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="c1"># last_output: [batch_size, hidden_dim]
</span>        <span class="n">prediction</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fc</span><span class="p">(</span><span class="n">last_output</span><span class="p">)</span>
        <span class="c1"># prediction: [batch_size, output_dim]
</span>        <span class="k">return</span> <span class="n">prediction</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define hyperparameters
</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">word_to_index</span><span class="p">)</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">word_to_index</span><span class="p">)</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>

<span class="c1"># Convert data and targets to PyTorch tensors
</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">long</span><span class="p">)</span>

<span class="c1"># Create DataLoader
</span><span class="n">dataset</span> <span class="o">=</span> <span class="nc">TensorDataset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
<span class="n">dataloader</span> <span class="o">=</span> <span class="nc">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> <p>```python</p> <h1 id="initialize-the-model-with-the-specified-hyperparameters">Initialize the model with the specified hyperparameters</h1> <p>model = BasicRNN(vocab_size=vocab_size, embedding_dim=embedding_dim, hidden_dim=hidden_size, output_dim=output_size).to(device)</p> <h1 id="define-the-loss-function">Define the loss function</h1> <p>loss_function = nn.CrossEntropyLoss()</p> <h1 id="choose-an-optimizer">Choose an optimizer</h1> <p>optimizer = optim.Adam(model.parameters(), lr=learning_rate)</p> <h1 id="function-to-train-the-model">Function to train the model</h1> <p>def train_model(model, dataloader, optimizer, loss_function, num_epochs, device): model.train() # Set the model to training mode for epoch in range(num_epochs): total_loss = 0 for inputs, targets in dataloader: inputs, targets = inputs.to(device), targets.to(device) # Transfer data to GPU optimizer.zero_grad() # Clear the gradients predictions = model(inputs) # Forward pass: compute the output class given a batch of inputs loss = loss_function(predictions, targets) # Compute the loss loss.backward() # Backward pass: compute the gradient of the loss w.r.t. the model’s parameters optimizer.step() # Perform a single optimization step (parameter update) total_loss += loss.item() print(f’Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader)}’) ```</p>]]></content><author><name></name></author><category term="posts"/><category term="DeepLearning"/><category term="NLP"/><summary type="html"><![CDATA[NLP tokenization and embedding layer]]></summary></entry><entry><title type="html">Tokenization and Embedding Layer</title><link href="https://imilesho.github.io/blog/2024/tokenization-embedding-layer/" rel="alternate" type="text/html" title="Tokenization and Embedding Layer"/><published>2024-02-13T12:00:00+00:00</published><updated>2024-02-13T12:00:00+00:00</updated><id>https://imilesho.github.io/blog/2024/tokenization-embedding-layer</id><content type="html" xml:base="https://imilesho.github.io/blog/2024/tokenization-embedding-layer/"><![CDATA[<h2 id="1-tokenization-example">1. Tokenization Example</h2> <p>Tokenization is the process of converting a sequence of characters (like a sentence or a paragraph) into a sequence of tokens. Tokens can be words, characters, or subwords. For instance, consider the sentence:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="sh">"</span><span class="s">Hello, world! This is a tokenization example.</span><span class="sh">"</span>
</code></pre></div></div> <p>Tokenizing this sentence at the word level would result in a list of tokens like:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="sh">"</span><span class="s">Hello</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">world</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">!</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">This</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">is</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">a</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">tokenization</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">example</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">.</span><span class="sh">"</span><span class="p">]</span>
</code></pre></div></div> <p>In machine learning models, these tokens are then typically converted into numerical IDs to be processed. For example, if we assign a unique ID to each token, the tokenized sentence might be represented as:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
</code></pre></div></div> <p>where each number corresponds to a unique token in the dataset.</p> <h2 id="2-embedding-layer-vs-word2vec-or-glove">2. Embedding Layer vs. Word2Vec or GloVe</h2> <p>Embedding Layer: An embedding layer is a part of neural network models that converts token IDs into dense vectors of a fixed size. It’s essentially a lookup table that learns the embeddings (vector representations) of words during the training process. The main advantage of an embedding layer is that it can learn task-specific word embeddings, meaning the embeddings are optimized for the specific dataset and task the model is trained on.</p> <p>Word2Vec and GloVe: Word2Vec and GloVe are methods for pre-training word embeddings using large corpora of text data. These methods produce pre-trained word embeddings that can be used as the initial weights for an embedding layer or directly in various natural language processing (NLP) tasks. Word2Vec uses local context information of words (i.e., neighboring words) to learn embeddings, while GloVe is based on global word co-occurrence statistics. Unlike the embeddings learned by a neural network’s embedding layer during a specific task, Word2Vec and GloVe embeddings are not task-specific but are rather general-purpose representations of words based on their usage in a large text corpus.</p> <h3 id="key-differences">Key Differences:</h3> <p>Task-specific vs. General-purpose: Embedding layers learn task-specific embeddings during the training of a model, while Word2Vec and GloVe provide general-purpose pre-trained embeddings.</p> <p>Training Data: Embedding layers are trained with the model on the task-specific data, whereas Word2Vec and GloVe embeddings are pre-trained on large, general text corpora.</p> <p>Flexibility: Embedding layers offer the flexibility to learn embeddings that are specifically tuned to the nuances of the task at hand, which can be advantageous for performance on that task. In contrast, Word2Vec and GloVe offer the advantage of leveraging large-scale data and can be particularly useful when the task-specific training data is limited.</p> <p>In summary, the choice between using an embedding layer and pre-trained embeddings like Word2Vec or GloVe depends on the specific requirements of your NLP task, including the size and nature of your dataset, and whether task-specific or general-purpose word representations are more suitable for your application.</p>]]></content><author><name></name></author><category term="notes"/><category term="DeepLearning"/><category term="NLP"/><summary type="html"><![CDATA[NLP tokenization and embedding layer]]></summary></entry><entry><title type="html">AWS EC2 Notes</title><link href="https://imilesho.github.io/blog/2024/AWSEC2/" rel="alternate" type="text/html" title="AWS EC2 Notes"/><published>2024-02-07T12:00:00+00:00</published><updated>2024-02-07T12:00:00+00:00</updated><id>https://imilesho.github.io/blog/2024/AWSEC2</id><content type="html" xml:base="https://imilesho.github.io/blog/2024/AWSEC2/"><![CDATA[<h2 id="aws-ec2">AWS EC2</h2> <h3 id="elastic-block-store-ebs">Elastic Block Store (EBS)</h3> <h4 id="ebs-volume-types">EBS Volume Types</h4> <h4 id="ebs-snapshots">EBS Snapshots</h4> <h3 id="elastic-file-system-efs">Elastic File System (EFS)</h3> <h3 id="ec2-instance-types">EC2 Instance Types</h3> <h3 id="ec2-instance-lifecycle">EC2 Instance Lifecycle</h3> <h3 id="ec2-instance-states">EC2 Instance States</h3> <h3 id="ec2-instance-metadata">EC2 Instance Metadata</h3> <h3 id="ec2-instance-user-data">EC2 Instance User Data</h3>]]></content><author><name></name></author><category term="posts"/><category term="AWS"/><category term="EC2"/><category term="EBS"/><category term="EFS"/><summary type="html"><![CDATA[Notes on AWS EC2]]></summary></entry><entry><title type="html">Docker Notes</title><link href="https://imilesho.github.io/blog/2024/Docker/" rel="alternate" type="text/html" title="Docker Notes"/><published>2024-02-07T12:00:00+00:00</published><updated>2024-02-07T12:00:00+00:00</updated><id>https://imilesho.github.io/blog/2024/Docker</id><content type="html" xml:base="https://imilesho.github.io/blog/2024/Docker/"><![CDATA[<h2 id="commands-notes">Commands Notes</h2> <p>The docker build -t myapp-frontend . command is used to create a Docker image from the Dockerfile in the current directory, which is denoted by the . at the end of the command. Here’s the breakdown:</p> <p>docker build: This is the Docker command to build a new image. -t myapp-frontend: The -t flag tags the new image with the name myapp-frontend. This name is what you use to refer to the image when you want to run a container from it. .: This specifies the build context to the current directory. Docker will look here for the Dockerfile and all files that are copied into the image.</p> <p>The docker run -d -p 3000:3000 –name my-frontend-container myapp-frontend command is used to run a Docker container based on the myapp-frontend image. Here’s the breakdown:</p> <p>docker run: This command is used to run a Docker container. -d: This flag tells Docker to run the container in detached mode, which means the container runs in the background and does not block the terminal. -p 3000:3000: This option maps the container’s port 3000 to port 3000 on the host machine, so that you can access the application using http://localhost:3000 on your browser. In the option -p 3000:3000, the first 3000 refers to the port on the host machine, and the second 3000 refers to the port inside the container. So when you visit http://localhost:3000 on your host machine, Docker routes that request to port 3000 on the container running your application. –name my-frontend-container: This assigns the name my-frontend-container to the running container, so you can easily refer to it with other Docker commands. myapp-frontend: This specifies the image to use to create the container, which is the image you previously built with the docker build command.</p>]]></content><author><name></name></author><category term="posts"/><category term="AWS"/><category term="EC2"/><category term="EBS"/><category term="EFS"/><summary type="html"><![CDATA[Notes on AWS EC2]]></summary></entry><entry><title type="html">Python Review Notes</title><link href="https://imilesho.github.io/blog/2024/PythonReview/" rel="alternate" type="text/html" title="Python Review Notes"/><published>2024-02-07T12:00:00+00:00</published><updated>2024-02-07T12:00:00+00:00</updated><id>https://imilesho.github.io/blog/2024/PythonReview</id><content type="html" xml:base="https://imilesho.github.io/blog/2024/PythonReview/"><![CDATA[<h2 id="python-review">Python Review</h2> <p>Here are some important notes on Python regarding the reason why we use Python, the setup, the language basics, some practical tips, and some great references.</p> <h3 id="why-python">why Python?</h3> <ul> <li>Widely used</li> <li>General purpose programming language</li> <li>Scientific compututation functionality similar to MATLAB</li> <li>Used by major deep learning libraries such as PyTorch and TensorFlow</li> </ul> <h3 id="setup">Setup</h3> <ul> <li>Environment setup <ul> <li>Problem <ul> <li>Different versions of Python</li> <li>Different versions of libraries (countless)</li> <li>Even same library versions have different versions</li> </ul> </li> <li>Solution <ul> <li>Use virtual environment</li> <li>Use conda</li> <li>Use pipenv</li> <li>Use Docker</li> </ul> </li> </ul> </li> </ul> <p>Common workflow</p> <ul> <li>Keep multiple Python environments that are isolated from each other</li> <li>Each environment has its own Python version and libraries</li> <li>Each environment can be easily replicated</li> </ul> <p>Anaconda is a popular Python environment/package manager</p> <ul> <li>Create environments <ul> <li>$ conda create -n <environment_name> // -n indicates the name of the environment</environment_name></li> <li>$ conda create -n <environment_name> python=3.8 // specify the version of Python</environment_name></li> <li>$ conda create -f <environment.yml> // create environment from a file</environment.yml></li> </ul> </li> <li>Activate/deactivate environments <ul> <li>$ conda activate <environment_name></environment_name></li> <li>$ conda deactivate // deactivate the current environment</li> </ul> </li> <li>Export environments <ul> <li>$ conda env list // list all environments</li> <li>$ conda activate <environment_name> // activate the environment first</environment_name></li> <li>$ conda env export &gt; environment.yml // export the environment to a file</li> </ul> </li> </ul> <h3 id="python-basics">Python Basics</h3> <ul> <li>Common Operations <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This is a comment
</span><span class="n">x</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
<span class="nf">print</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
<span class="n">x</span> <span class="o">**</span> <span class="n">y</span> <span class="c1"># exponentiation
</span><span class="n">x</span> <span class="o">/</span> <span class="n">y</span> <span class="c1"># division, the result is 3.3333333333333335
</span><span class="n">x</span> <span class="o">//</span> <span class="n">y</span> <span class="c1"># floor division, the result is 3
</span><span class="n">x</span> <span class="o">%</span> <span class="n">y</span> <span class="c1"># modulo, the result is 1
</span><span class="n">x</span> <span class="o">/</span> <span class="nf">float</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># the result is 3.3333333333333335
</span><span class="nf">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> + </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># convert to string
</span></code></pre></div> </div> </li> <li>Built-in Values <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="bp">False</span>
<span class="n">x</span> <span class="o">=</span> <span class="bp">None</span> <span class="c1"># Variables can be assigned None representing the absence of a value
</span><span class="n">array</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> <span class="c1"># List can contain None
</span><span class="k">def</span> <span class="nf">func</span><span class="p">():</span>
<span class="k">return</span> <span class="bp">None</span> <span class="c1"># Functions can return None, used to indicate that the function does not return a value
</span></code></pre></div> </div> </li> <li>Python is a strongly-typed and dynamically-typed language <ul> <li>Strongly-typed: The type of a variable can not be coerced into another type like in JavaScript <ul> <li>e.g. “1” + 2 // TypeError: can only concatenate str (not “int”) to str</li> </ul> </li> <li>Dynamically-typed: The type of a variable is determined at runtime, not at compile time. Variables are names of values or objects references. Variables can be reassigned to values of a different type. <ul> <li>e.g. x = 1 // x is an integer</li> <li>x = “hello” // x is a string</li> </ul> </li> </ul> </li> <li>Execution of Python code <ul> <li>Python code is first interpreted into bytecode(.pyc) and then compiled by a VM implementation into machine instructions. (Most commonly using C.)</li> <li>Python is slower, but it can run highly optimized C/C++ subroutines which makes scientific computing (e.g. matrix multiplication) very fast.</li> </ul> </li> </ul> <h3 id="python-common-data-structures">Python Common Data Structures</h3> <p>Collections</p> <ul> <li>List <ul> <li>Ordered, mutable, allows duplicate elements</li> <li>e.g. [1, 2, 3, 4, 5] ```python names = [‘Alice’, ‘Bob’, ‘Charlie’] #index 0 1 2 #index -3 -2 -1 names[0] # ‘Alice’ print(len(names)) # get the length of the list print(names) # [‘Alice’, ‘Bob’, ‘Charlie’] names.append(‘David’) # [‘Alice’, ‘Bob’, ‘Charlie’, ‘David’]</li> </ul> </li> </ul> <p>my_empty_list = [] my_empty_list = list()</p> <p>stuff = [1, 2, [“hello”, “world”], True, -0.12, None]</p> <h1 id="list-slicing">List Slicing</h1> <p>names[-1] # ‘Charlie’ names[1:2] # [‘Bob’] numbers = [0, 1, 2, 3, 4, 5, 6] numbers[0:3] == numbers[:3] == [0, 1, 2] numbers[5:] == numbers[5:7] == [5, 6] numbers[:] == numbers == [0, 1, 2, 3, 4, 5, 6] numbers[-1] == 6 # Negative index wraps around numbers[-3:] == [4, 5, 6] numbers[3:-2] == [3, 4] # Can mix and match</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
- Tuple
  - Ordered, immutable, allows duplicate elements
  - e.g. (1, 2, 3, 4, 5)
```python
names = ('Alice', 'Bob', 'Charlie')
#index      0       1        2
#index     -3      -2       -1
names[0] # 'Alice'
print(len(names)) # get the length of the tuple
print(names) # ('Alice', 'Bob', 'Charlie')
names[0] = 'David' # TypeError: 'tuple' object does not support item assignment
empty_tuple = ()
empty_tuple = tuple()
single = (1,) # single element tuple, otherwise it's just a number
</code></pre></div></div> <ul> <li>Dictionary <ul> <li>Unordered, mutable, indexed, no duplicate elements</li> <li>e.g. {‘name’: ‘Alice’, ‘age’: 25} ```python phonebook = {} phonebook = dict() phonebook = {‘Zach’: ‘12-37’} # dictionary with one key-value pair phonebook[‘Alice’] = ‘123-456’ # add a new key-value pair</li> </ul> </li> </ul> <p>print(‘Alice’ in phonebook) # True, check if a key exists, can not check for values print(‘Bob’ in phonebook) # False print(phonebook[‘Alice’]) # ‘123-456’ print(phonebook[‘Bob’]) # KeyError: ‘Bob’</p> <p>print(phonebook.get(‘Alice’)) # ‘123-456’ print(phonebook.get(‘Bob’)) # None</p> <p>print(phonebook) # {‘Alice’: ‘123-456’, ‘Zach’: ‘12-37’}</p> <p>phonebook[‘Alice’] = ‘321-456’ # update a value del phonebook[‘Alice’] # delete a key-value pair phonebook.clear() # remove all key-value pairs</p> <p>print(phonebook) # {}</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
- Set
  - Unordered, mutable, no duplicate elements
  - e.g. {1, 2, 3, 4, 5}
```python
basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}
print(basket)                      # show that duplicates have been removed
{'orange', 'banana', 'pear', 'apple'}
'orange' in basket                 # fast membership testing
True
'crabgrass' in basket
False

# Demonstrate set operations on unique letters from two words

a = set('abracadabra')
b = set('alacazam')
a                                  # unique letters in a
{'a', 'r', 'b', 'c', 'd'}
a - b                              # letters in a but not in b
{'r', 'd', 'b'}
a | b                              # letters in a or b or both
{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}
a &amp; b                              # letters in both a and b
{'a', 'c'}
a ^ b                              # letters in a or b but not both
{'r', 'd', 'b', 'm', 'z', 'l'}
</code></pre></div></div> <ul> <li>Loops ```python names = [‘Alice’, ‘Bob’, ‘Charlie’] for i, name in enumerate(names): print(i, name)</li> </ul> <p>phonebook = {‘Alice’: ‘123-456’, ‘Bob’: ‘456-789’, ‘Charlie’: ‘789-123’} for name, number in phonebook.items(): print(name, number)</p> <p>for key, value in enumerate(phonebook): print(key, value)</p> <p>for name in phonebook.keys(): print(name)</p> <p>for number in phonebook.values(): print(number)</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
- Classes

```python
class Dog:
  # Constructor `a = Dog('Fido', 3)`
  def __init__(self, name, age):
    self.name = name # refer instance variables with `self`
    self.age = age # instance variables are public by default

  def bark(self):
    print('Woof!')

  def birthday(self):
    self.age += 1

  def get_name(self):
    return self.name

  def get_age(self):
    return self.age

  def set_name(self, name):
    self.name = name

  def set_age(self, age):
    self.age = age

  # same function name, different parameters which is called method overloading
  def play(self, other_dog):
    print(self.name, 'plays with', other_dog.name)
  
  def play(self):
    print(self.name, 'plays with self')



fido = Dog('Fido', 3)
fido.bark() # Woof!
fido.birthday()
print(fido.get_age()) # 4

# Inheritance
class Husky(Dog):
  # redefine the constructor
  def __init__(self, name, age, color):
    super().__init__(name, age) # call the parent class constructor
    self.color = color
  def birthday(self):
    self.age += 5 # override the parent class method
</code></pre></div></div> <h3 id="introduction-to-numpy">Introduction to NumPy</h3> <ul> <li>NumPy is optimized for matrix and vector operations</li> <li>Makes use of C/C++ subroutines and memory-efficient data structures. (Lots of computation can be efficiently represneted as vectors.)</li> <li>NumPy arrays are homogeneous, i.e. all elements are of the same type</li> <li>Main data structure is the numpy.ndarray. The constructor function is numpy.array()</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span> <span class="c1"># 1D array, [1, 2, 3], shape is (3,)
</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span> <span class="p">,</span><span class="mi">5</span><span class="p">]])</span> <span class="c1"># 2D array, [[3, 4, 5]], shape is (1, 3)
</span><span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span> <span class="c1"># 2D array, [[1, 2, 3], [4, 5, 6]], shape is (2, 3)
</span><span class="nf">print</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (3,)
</span><span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (1, 3)
</span><span class="nf">print</span><span class="p">(</span><span class="n">z</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># (2, 3)
</span>
<span class="c1"># Create arrays with zeros, ones, and random numbers
</span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> <span class="c1"># 2x3 array of zeros
</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="c1"># 1x2 array of ones
</span><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="c1"># 2x2 array of random numbers, uniform distribution, [0, 1)
</span><span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 2x2 array of random numbers, normal distribution, mean 0, standard deviation 1
</span><span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="c1"># 2x2 array of random integers, [1, 10)
</span><span class="n">f</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="c1"># 2x2 array of random integers, [1, 5]
</span>
<span class="c1"># np.ndarray Operations
# Reductions: np.max(), np.min(), np.sum(), np.mean(), np.std(), np.var(). np.std() is the square root of np.var()
</span>
<span class="c1"># shape (3, 2)
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c1"># 6
</span><span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="c1"># [5, 6]
</span><span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span> <span class="c1"># [[5, 6]]
</span><span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># [2, 4, 6]
</span><span class="nf">print</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span> <span class="c1"># [[2], [4], [6]]
</span>
<span class="c1"># Matrix Operations: np.dot(), np.matmul(), np.linalg.norm, .T, etc.
# Infix operator(i.e. +, -, *, /, **) are element-wise operations
# Element-wise product of matrices A 。 B is A * B
# Element-wise division of matrices A / B is A / B
# Dot product and matrix vector product(between 1-D array vectors) are using np.dot()
</span><span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> 
<span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="c1"># matrix vector product
</span>
<span class="c1"># Matrix product/ multipication prefer np.matmul() over np.dot()
</span><span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span> <span class="c1"># matrix product
</span><span class="n">A</span> <span class="o">@</span> <span class="n">B</span> <span class="c1"># matrix product
</span>
<span class="c1"># Transpose
</span><span class="n">x</span><span class="p">.</span><span class="n">T</span> <span class="c1"># transpose of x
</span></code></pre></div></div> <ul> <li>Indexing and Slicing ```python x = np.random.random((3, 4)) x[:] # all elements keep shape x[0, :] # first row, shape is (4,) x[:, 0] # first column, shape is (3,) x[1, 1:3] # second row, second and third column, shape is (2,)</li> </ul> <h1 id="note-selecting-with-an-ndarray-list-or-tuple-will-preserve-the-shape">Note: selecting with an ndarray, list, or tuple will preserve the shape</h1> <p>x[(1, 2), :] # second and third row, shape is (2, 4) x[np.array([1, 2]), :] # second and third row, shape is (2, 4) x[[1, 2], :] # second and third row, shape is (2, 4)</p> <p>x[:, :, np.newaxis] # add a new axis, shape is (3, 4, 1)</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
- Broadcasting
  - allows for element-wise operations between arrays of different shapes

```python
x = np.random.random((3, 4)) # Random 3x4 matrix
y = np.random.random((3,1)) # Random 3x1 vector
z = np.random.random((1, 4)) # Random 1x4 vector

x + y # Adds y to each column of x
x * z # Multiplies each row of x by z element-wise
</code></pre></div></div> <ul> <li>Broadcasting generalize: NumPy compares their shapes element-wise. It starts with the trailing dimensions and works its way forward. Two dimensions are compatible when <ul> <li> <ol> <li>they are equal, or</li> </ol> </li> <li> <ol> <li>one of them is 1 (in which case, elements on the axis are repeated along the dimension) ```python a = np.random.random((3, 4)) b = np.random.random((3, 1)) c = np.random.random((3, ))</li> </ol> </li> </ul> </li> </ul> <p>b + b.T # works a + c # ValueError: operands could not be broadcast together with shapes (3,4) (3,) b + c # works, b is broadcasted to (3, 3), then element-wise addition</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
- Efficient Numpy Code
  - Avoid explicit for-loops over indices/axes at all costs. For-loops will dramatically slow down our code.(~10-100x).

```python
# Slow
x = np.random.random((1000, 1000))
y = np.zeros((1000, 1000))
for i in range(1000):
  for j in range(1000):
    y[i, j] = x[i, j] + 1

# Fast
x = np.random.random((1000, 1000))
y = x + 1
</code></pre></div></div> <ul> <li>Use NumPy’s built-in functions and operations whenever possible. They are highly optimized and run much faster than their Python counterparts.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Slow
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>

<span class="c1"># Fast
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>Use NumPy’s broadcasting feature to avoid unnecessary duplication of data. This will save memory and speed up your code.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Slow
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="c1"># Fast
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
</code></pre></div></div> <ul> <li>Use NumPy’s built-in linear algebra functions for matrix operations. They are highly optimized and run much faster than their Python counterparts.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Slow
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
      <span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">y</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>

<span class="c1"># Fast
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div> <h3 id="pratical-python-tips">Pratical Python Tips</h3> <ul> <li>Use list comprehensions to create lists ```python <h1 id="slow">Slow</h1> <p>squares = [] for i in range(10): squares.append(i ** 2)</p> </li> </ul> <h1 id="fast">Fast</h1> <p>squares = [i ** 2 for i in range(10)]</p> <h1 id="can-also-use-conditionals">can also use conditionals</h1> <p>squares = [i ** 2 for i in range(10) if i % 2 == 0]</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
- Convenient Syntax
```python
# Swap two variables
a, b = 1, 2
a, b = b, a

# Multiple assignment
a, b, c = 1, 2, 3
a, b, c = ('Alice', 25, True)

# Unpack a list
x = [1, 2, 3]
a, b, c = x

# Return multiple values from a function
def f():
  return 1, 2, 3
a, b, c = f()

# Joining list of strings with a delimiter
names = ['Alice', 'Bob', 'Charlie']
', '.join(names) # 'Alice, Bob, Charlie'

# String literals with both single and double quotes
s = "Hello, 'world'"
s = 'Hello, "world"'
</code></pre></div></div> <ul> <li>Debugging Tips: use interactive shell <ul> <li>Python has no integer overflow</li> <li>Try out syntax</li> <li>array.shape, array.dtype, type(array)</li> <li>import pdb; pdb.set_trace() # set a breakpoint</li> <li>or breakpoint() # Python 3.7+, set a breakpoint</li> <li>print(f’My name is {name}’) # f-string, Python 3.6+, string interpolation</li> </ul> </li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">array</span><span class="p">.</span><span class="n">shape</span> <span class="c1"># get the shape of the numpy array
</span><span class="n">array</span><span class="p">.</span><span class="n">dtype</span> <span class="c1"># get the element data type of the numpy array
</span><span class="nf">type</span><span class="p">(</span><span class="n">array</span><span class="p">)</span> <span class="c1"># get the type of a variable
</span></code></pre></div></div> <ul> <li>Common Errors <ul> <li>SyntaxError: invalid syntax</li> <li>NameError: name ‘x’ is not defined</li> <li>TypeError: can only concatenate str (not “int”) to str</li> <li>ValueError: invalid literal for int() with base 10: ‘hello’</li> <li>IndexError: list index out of range</li> <li>KeyError: ‘Alice’</li> <li>AttributeError: ‘list’ object has no attribute ‘append’</li> <li>IndentationError: expected an indented block</li> <li>ZeroDivisionError: division by zero</li> <li>FileNotFoundError: [Errno 2] No such file or directory: ‘file.txt’</li> <li>ModuleNotFoundError: No module named ‘numpy’</li> </ul> </li> </ul> <h3 id="other-great-references">Other Great References</h3> <ul> <li>Official Python 3 documentation: https://docs.python.org/3/</li> <li>Official Anaconda user guide: https://docs.conda.io/projects/conda/en/latest/user-guide/index.html</li> <li>Official NumPy documentation: https://numpy.org/doc/stable/</li> </ul>]]></content><author><name></name></author><category term="posts"/><category term="Python"/><category term="Foundation"/><summary type="html"><![CDATA[Notes on Python]]></summary></entry><entry><title type="html">Apache License, Version 2.0</title><link href="https://imilesho.github.io/blog/2024/ApacheLicense/" rel="alternate" type="text/html" title="Apache License, Version 2.0"/><published>2024-01-30T23:00:00+00:00</published><updated>2024-01-30T23:00:00+00:00</updated><id>https://imilesho.github.io/blog/2024/ApacheLicense</id><content type="html" xml:base="https://imilesho.github.io/blog/2024/ApacheLicense/"><![CDATA[<h2 id="apache-license-version-20">Apache License, Version 2.0</h2> <p>We can use open-source code licensed under the Apache License, Version 2.0 (ALv2), in a commercial product for free. The Apache License is one of the permissive open-source licenses, allowing you to use, modify, and distribute the licensed software in both open-source and proprietary projects. Here are some key points about using ALv2 licensed software in commercial products:</p> <h3 id="permissive-license">Permissive License:</h3> <p>ALv2 is a permissive license, meaning it allows for broad freedom with the software, including commercial use, without a significant burden of requirements compared to copyleft licenses (like GPL).</p> <h3 id="commercial-use-allowed">Commercial Use Allowed:</h3> <p>You can use, modify, and distribute the original or modified software for any purpose, including commercial, without having to pay royalties to the original authors.</p> <h3 id="redistribution">Redistribution:</h3> <p>When you redistribute the code or derivative works, you need to include a copy of the Apache License, provide a notice that you have modified the original software (if applicable), and include any NOTICE file provided with the original software. These requirements are designed to ensure proper attribution and to inform recipients of the terms under which the software is provided.</p> <h3 id="patent-grant">Patent Grant:</h3> <p>The license includes an express grant of patent rights from contributors to users, protecting you against patent claims from contributors related to their contributions to the software.</p> <h3 id="no-warranty">No Warranty:</h3> <p>Like most open-source software, the Apache-licensed software is provided “as is,” without warranties of any kind. The responsibility for assessing the software’s suitability and managing any risks associated with its use lies with you.</p> <h3 id="liability">Liability:</h3> <p>The license limits the liability of contributors for any damages that may arise from the use of the software.</p> <p>The Apache License’s permissions, conditions, and limitations are designed to encourage the use of Apache-licensed software in both open-source and proprietary projects, making it a popular choice for commercial applications. However, it is always a good practice to review the license terms yourself or consult with legal counsel to ensure your intended use complies with the license and to understand any obligations it may impose.</p>]]></content><author><name></name></author><category term="posts"/><category term="OpenSource"/><category term="ApacheLicense"/><summary type="html"><![CDATA[Using open-source code licensed under the Apache License, Version 2.0 in commercial products]]></summary></entry><entry><title type="html">Troubleshooting Nginx and uWSGI</title><link href="https://imilesho.github.io/blog/2024/NginxAnduWSGITroubleShooting/" rel="alternate" type="text/html" title="Troubleshooting Nginx and uWSGI"/><published>2024-01-30T12:00:00+00:00</published><updated>2024-01-30T12:00:00+00:00</updated><id>https://imilesho.github.io/blog/2024/NginxAnduWSGITroubleShooting</id><content type="html" xml:base="https://imilesho.github.io/blog/2024/NginxAnduWSGITroubleShooting/"><![CDATA[<h1 id="troubleshooting-nginx-and-uwsgi-resolving-permission-denied-errors">Troubleshooting Nginx and uWSGI: Resolving Permission Denied Errors</h1> <p>In the dynamic world of web server management, encountering errors is a common part of the job. One such challenge involves the integration of Nginx and uWSGI, especially when dealing with Unix sockets and permission issues. In this blog post, we’ll explore a real-life scenario where Nginx was unable to connect to a uWSGI socket, leading to a “Permission Denied” error. We’ll walk through the problem and provide a step-by-step guide to diagnose and solve these issues.</p> <h2 id="the-problem">The Problem</h2> <p>The error in question was logged by Nginx as follows:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2024/01/28 23:10:39 [crit] 223649#223649: *2 connect() to unix:/home/ubuntu/myFlashCards/computer-science-flash-cards/flash_cards.sock failed (13: Permission denied) while connecting to upstream...
</code></pre></div></div> <p>This error indicated that Nginx, acting as a reverse proxy, was unable to connect to the <code class="language-plaintext highlighter-rouge">flash_cards.sock</code> Unix socket used by a uWSGI application. This type of error is typically a result of incorrect permissions or ownership settings on the socket file or the directories leading to it.</p> <h2 id="step-by-step-diagnosis-and-resolution">Step-by-Step Diagnosis and Resolution</h2> <h3 id="step-1-check-socket-file-permissions">Step 1: Check Socket File Permissions</h3> <p>The first step is to inspect the permissions of the socket file:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">ls</span> <span class="nt">-l</span> /home/ubuntu/myFlashCards/computer-science-flash-cards/flash_cards.sock
</code></pre></div></div> <p>The output showed correct permissions (<code class="language-plaintext highlighter-rouge">srw-rw----</code>) and ownership (<code class="language-plaintext highlighter-rouge">ubuntu:www-data</code>), indicating that the socket file itself was not the issue.</p> <h3 id="step-2-examine-directory-permissions">Step 2: Examine Directory Permissions</h3> <p>Next, we checked the permissions of the directories containing the socket file:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">ls</span> <span class="nt">-ld</span> /home/ubuntu
<span class="nb">ls</span> <span class="nt">-ld</span> /home/ubuntu/myFlashCards
</code></pre></div></div> <p>The output revealed a potential issue:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>drwxr-x--- 8 ubuntu ubuntu 4096 Jan 28 23:10 /home/ubuntu
drwxrwxr-x 3 ubuntu ubuntu 4096 Jan 28 22:56 /home/ubuntu/myFlashCards
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">/home/ubuntu</code> directory had restricted permissions, preventing the <code class="language-plaintext highlighter-rouge">www-data</code> user (under which Nginx runs) from accessing the socket file inside it.</p> <h3 id="step-3-adjusting-permissions">Step 3: Adjusting Permissions</h3> <p>To resolve this, we modified the permissions of the <code class="language-plaintext highlighter-rouge">/home/ubuntu</code> directory to allow traversal by the <code class="language-plaintext highlighter-rouge">www-data</code> user:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod </span>o+x /home/ubuntu
</code></pre></div></div> <p>This command added execute permission for others, enabling the necessary traversal access.</p> <h3 id="step-4-restart-services">Step 4: Restart Services</h3> <p>After adjusting the permissions, both Nginx and uWSGI services were restarted to apply the changes:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">sudo </span>systemctl restart nginx
<span class="nb">sudo </span>systemctl restart your_uwsgi_service  <span class="c"># Replace with your specific uWSGI service name</span>
</code></pre></div></div> <h3 id="step-5-verify-the-solution">Step 5: Verify the Solution</h3> <p>Finally, we checked the Nginx error logs again to confirm that the “Permission Denied” error was resolved.</p> <h2 id="conclusion">Conclusion</h2> <p>Dealing with Nginx and uWSGI can sometimes be challenging, especially when it comes to permissions and access control. In this instance, a seemingly complex problem was resolved by a simple change in directory permissions. It’s a good reminder of the importance of understanding the underlying system’s architecture and permissions when managing web servers.</p> <p>Remember, always approach such changes with caution, especially in a production environment, to avoid unintended security risks. Happy troubleshooting!</p>]]></content><author><name></name></author><category term="posts"/><category term="Nginx"/><category term="uWSGI"/><category term="Troubleshooting"/><summary type="html"><![CDATA[Diagnosing and solving Nginx and uWSGI permission issues]]></summary></entry><entry><title type="html">Optuna</title><link href="https://imilesho.github.io/blog/2024/Optuna/" rel="alternate" type="text/html" title="Optuna"/><published>2024-01-24T16:00:00+00:00</published><updated>2024-01-24T16:00:00+00:00</updated><id>https://imilesho.github.io/blog/2024/Optuna</id><content type="html" xml:base="https://imilesho.github.io/blog/2024/Optuna/"><![CDATA[<h2 id="optuna-a-hyperparameter-optimization-framework"><a href="&quot;https://optuna.readthedocs.io/en/stable/index.html&quot;">Optuna: A hyperparameter optimization framework</a></h2> <p>Optuna is an automatic hyperparameter optimization software framework, particularly designed for machine learning. It features an imperative, define-by-run style user API. Thanks to our define-by-run API, the code written with Optuna enjoys high modularity, and the user of Optuna can dynamically construct the search spaces for the hyperparameters.</p> <h1 id="key-features">Key Features</h1> <p>Optuna has modern functionalities as follows:</p> <ul> <li> <p>Lightweight, versatile, and platform agnostic architecture</p> </li> <li> <p>Handle a wide variety of tasks with a simple installation that has few requirements.</p> </li> <li> <p>Pythonic search spaces</p> </li> <li> <p>Define search spaces using familiar Python syntax including conditionals and loops.</p> </li> <li> <p>Efficient optimization algorithms</p> </li> <li> <p>Adopt state-of-the-art algorithms for sampling hyperparameters and efficiently pruning unpromising trials.</p> </li> <li> <p>Easy parallelization</p> </li> <li> <p>Scale studies to tens or hundreds of workers with little or no changes to the code.</p> </li> <li> <p>Quick visualization</p> </li> <li> <p>Inspect optimization histories from a variety of plotting functions.</p> </li> </ul>]]></content><author><name></name></author><category term="posts"/><category term="Optuna"/><category term="DeepLearning"/><summary type="html"><![CDATA[A hyperparameter optimization framework]]></summary></entry><entry><title type="html">How to Gracefully Add a Final Message to Online Conversations</title><link href="https://imilesho.github.io/blog/2024/English01/" rel="alternate" type="text/html" title="How to Gracefully Add a Final Message to Online Conversations"/><published>2024-01-23T12:00:00+00:00</published><updated>2024-01-23T12:00:00+00:00</updated><id>https://imilesho.github.io/blog/2024/English01</id><content type="html" xml:base="https://imilesho.github.io/blog/2024/English01/"><![CDATA[<h1 id="how-to-gracefully-add-a-final-message-to-online-conversations">How to Gracefully Add a Final Message to Online Conversations</h1> <h2 id="in-a-formal-or-professional-setting">In a Formal or Professional Setting</h2> <p>When your conversation is more on the professional side, clarity and politeness are key. Here’s how you can add that last piece of information:</p> <ol> <li><strong>“Before signing off, I would like to add…“</strong> - This preface is courteous and signals that you are concluding with an important point.</li> <li><strong>“Just one more thing before we conclude…“</strong> - It’s a respectful way to signal that you have a final point to make, showing that you value the other person’s time.</li> <li><strong>“Lastly, I’d like to mention…“</strong> - This transition smoothly directs attention to your closing remarks, wrapping up the conversation neatly.</li> <li><strong>“Before we end, I want to ensure we’ve covered…“</strong> - This is particularly useful for ensuring all critical points have been discussed, demonstrating thoroughness and attention to detail.</li> <li><strong>“In closing, I’d like to add a final note…“</strong> - A clear indication that your next point will conclude the conversation, perfect for summarizing or emphasizing an important takeaway.</li> </ol> <h2 id="in-an-informal-or-casual-setting">In an Informal or Casual Setting</h2> <p>Casual conversations afford more flexibility, but it’s still important to be considerate:</p> <ol> <li><strong>“Oh, just one more thing before we wrap up…“</strong> - This informal sign-off is friendly and light, ideal for conversations with friends or casual acquaintances.</li> <li><strong>“Before we call it a day, I remembered…“</strong> - A relaxed way to introduce a final thought, implying a laid-back and spontaneous addition.</li> <li><strong>“Oh, by the way, before we finish…“</strong> - Perfect for adding something that just came to mind, maintaining a conversational and casual tone.</li> <li><strong>“Almost forgot to mention…“</strong> - Implies that what you’re about to say is a casual afterthought, keeping the mood light.</li> <li><strong>“One last thing before we go…“</strong> - A straightforward, no-frills way to introduce your final point in a friendly manner.</li> </ol> <h2 id="adding-a-follow-up">Adding a Follow-Up</h2> <p>Sometimes, your final message might be about continuing the conversation at a later time:</p> <ol> <li><strong>“Let’s touch base on this later.”</strong> - Indicates a desire to revisit the discussion, showing ongoing engagement.</li> <li><strong>“I’ll follow up with more details.”</strong> - A commitment to provide further information, demonstrating reliability.</li> <li><strong>“Expect an email from me with further information.”</strong> - Sets the expectation for continued communication, ensuring the recipient looks out for more details.</li> </ol> <h2 id="expressing-appreciation">Expressing Appreciation</h2> <p>No matter the setting, ending on a note of gratitude can enhance your message:</p> <ol> <li><strong>“Thanks for your time, and also…“</strong> - Acknowledges the other person’s investment in the conversation before adding your final point.</li> <li><strong>“I appreciate your patience, and one more thing…“</strong> - Shows gratitude for the recipient’s attention and engagement.</li> <li><strong>“Thank you for the discussion. Additionally…“</strong> - A polite way to both appreciate the conversation and add a concluding remark.</li> </ol>]]></content><author><name></name></author><category term="posts"/><category term="English"/><category term="Message"/><summary type="html"><![CDATA[English Writing]]></summary></entry></feed>